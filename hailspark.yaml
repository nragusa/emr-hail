AWSTemplateFormatVersion: '2010-09-09'
Description: Provision an EMR/Spark cluster with Hail and Jupyter Notebooks
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    - Label:
        default: EMR Options
      Parameters:
        - VPC
        - Subnet
        - CoreNodeCount
        - DiskSizeGB
        - InstanceType
        - AccessFromCIDRBlock
        - EC2KeyName
    - Label:
        default: Jupyter Options
      Parameters:
        - JupyterPort
        - JupyterPassword
    - Label:
        default: Hail Options
      Parameters:
        - HailBuildOutputS3Path
        - HailBuildHailVersion
        - HailBuildSparkVersion
    - Label:
        default: Tags
      Parameters:
        - NameTag
        - OwnerTag
        - PurposeTag
    ParameterLabels:
      CoreNodeCount:
        default: Core Node Count
      DiskSizeGB:
        default: 'Disk Size (GB)'
      InstanceType:
        default: Instance Type
      AccessFromCIDRBlock:
        default: IP CIDR Block
      EC2KeyName:
        default: EC2 Key Pair Name
      JupyterPort:
        default: Jupyter Port
      JupyterPassword:
        default: Jupyter Password
      HailBuildOutputS3Path:
        default: S3 Output Path
      HailBuildHailVersion:
        default: Hail Version
      HailBuildSparkVersion:
        default: Spark Version
      NameTag:
        default: Name Tag
      OwnerTag:
        default: Owner Tag
      PurposeTag:
        default: Purpose Tag
Parameters:
  EnvironmentName:
    Type: String
    Description: >
      An environment name that will be prefixed to resource names including
      exported values. Should be unique per region.
  JupyterPassword:
    AllowedPattern: >-
      [a-zA-Z0-9!^*_+-]*
    ConstraintDescription: >
      Can only contain alphanumeric characters or the following
      special characters !^*-_+, between 8 and 28 characters
    Description: Password Jupyter Notebook login (between 8 and 28 characters)
    MaxLength: 28
    MinLength: 8
    NoEcho: true
    Type: String
  EC2KeyName:
    Description: SSH key pair to use for EMR node login
    Type: AWS::EC2::KeyPair::KeyName
  VPC:
    Description: VPC for EMR nodes.
    Type: AWS::EC2::VPC::Id
  Subnet:
    Description: Subnet for EMR nodes, from the VPC selected above
    Type: AWS::EC2::Subnet::Id
  CoreNodeCount:
    Description: Number of core nodes to provision (1-20)
    Type: Number
    MinValue: '1'
    MaxValue: '80'
    Default: '10'
  DiskSizeGB:
    Description: EBS Volume size (GB) for each node
    Type: Number
    MinValue: '50'
    MaxValue: '1000'
    Default: '500'    
  InstanceType:
    Type: String
    Default: m4.xlarge
    AllowedValues:
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.9xlarge
      - c5d.18xlarge
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.10xlarge
      - m4.16xlarge
      - c4.large
      - c4.xlarge
      - c4.2xlarge
      - c4.4xlarge
      - c4.8xlarge
      - r3.xlarge
      - r3.2xlarge
      - r3.4xlarge
      - r3.8xlarge
    Description: EMR node ec2 instance type - you can add more types by expanding
      on this list.
  EMRReleaseLabel:
    Type: String
    Default: emr-5.10.0
    Description: The EMR release label
    AllowedValues:
      - emr-5.16.0
      - emr-5.15.0
      - emr-5.14.0
      - emr-5.13.0
      - emr-5.12.1
      - emr-5.12.0
      - emr-5.11.1
      - emr-5.11.0
      - emr-5.10.0
      - emr-5.9.0
  OwnerTag:
    Type: String
    Default: Owner
    MinLength: 1
    Description: Your name - used to tag the cluster
  PurposeTag:
    Type: String
    MinLength: 1
    Default: Genomic
    Description: Purpose - used to tag the cluster
  NameTag:
    Type: String
    MinLength: 1
    Default: hail-blog
    Description: Environment name of the cluster
  AccessFromCIDRBlock:
    Type: String
    MinLength: 9
    Default: 0.0.0.0/0
    Description: Restrict WebUI access to specified address or range - default 'anywhere'
  JupyterPort:
    Type: Number
    Default: 8192
    Description: Port for Jupyter service to listen on
  HailBuildOutputS3Path:
    Type: String
    MinLength: 1
    Default: your-output-bucket/prefix
    Description: S3 bucket and prefix for saving the compiled Hail files
  HailBuildHailVersion:
    Type: String
    MinLength: 1
    Default: 0.2
    Description: Hail version to build
  HailBuildSparkVersion:
    Type: String
    MinLength: 1
    Default: 2.2.0
    Description: Spark version to compile Hail against
Resources:
  EMRBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
  AllowWebUIs:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Jupyter
      VpcId:
        Ref: VPC
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: !Ref JupyterPort
        ToPort: !Ref JupyterPort
        CidrIp:
          Ref: AccessFromCIDRBlock
  rEMREC2InstanceProfile:
    Properties:
      Path: "/"
      Roles:
      - Ref: rEMREC2Role
    Type: AWS::IAM::InstanceProfile
  rEMREC2Role:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
        Version: '2012-10-17'
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforEC2Role
      Policies:
      - PolicyName: Athena-for-EMR
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
          - Resource: "*"
            Action:
            - athena:*
            Effect: Allow
  rEMRServiceRole:
    Type: AWS::IAM::Role
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - elasticmapreduce.amazonaws.com
        Version: '2012-10-17'
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole
  SparkCluster:
    DependsOn: EMRCleanup
    Type: AWS::EMR::Cluster
    Properties:
      Applications:
      - Name: Hadoop
      - Name: Hive
      - Name: Spark
      - Name: Ganglia
      BootstrapActions:
        - Name: UpgradePython
          ScriptBootstrapAction:
            Path: file:/usr/bin/sudo
            Args:
            - "yum"
            - "-y"
            - "install"
            - "python36"
            - "python36-devel"
            - "python36-setuptools"
        - Name: InstallPythonDeps
          ScriptBootstrapAction:
            Path: file:/usr/bin/sudo
            Args:
            - "pip"
            - "install"
            - "pyserial"
            - "oauth"
            - "cheetah3"
            - "argparse"
            - "PrettyTable"
            - "wheel"
            - "pandas"
            - "parsimonious"
            - "tornado"
            # - "jupyter"
            - "numpy"
            # - "collections"
            # - "math"
            - "pprint"
            - "bokeh"
            - "scikit-learn"
            - "matplotlib"
            - "ggplot"
            - "decorator"
        # - Name: DownloadHailBins
        #   ScriptBootstrapAction:
        #     Path: "s3://emr-hail-0.2-us-east-1/download_hail_bin.sh"
        - Name: Build-Hail
          ScriptBootstrapAction:
            Path: "s3://emr-hail-0.2-us-east-1/build_hail.sh"
            Args:
            - "--output-path"
            - !Sub "s3://${HailBuildOutputS3Path}"
            - "--hail-version"
            - Ref: HailBuildHailVersion
            - "--spark-version"
            - Ref: HailBuildSparkVersion
        - Name: Install-Python-Jupyter
          ScriptBootstrapAction:
            Path: s3://aws-bigdata-blog/artifacts/aws-blog-emr-jupyter/install-jupyter-emr5.sh
            Args:
            - "--toree"
            - "--ds-packages"
            - "--ml-packages"
            - "--python-packages"
            - "ggplot"
            - "--password"
            - Ref: JupyterPassword
            - "--port"
            - Ref: JupyterPort
            - "--ssl"
            - "--cached-install"
            - "--spark-opts"
            - "--jars /home/hadoop/hail-all-spark.jar"
      Configurations:
      - Classification: spark-defaults
        ConfigurationProperties:
          spark.driver.extraClassPath: "/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:./hail-all-spark.jar"
          spark.executor.extraClassPath: "/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:./hail-all-spark.jar"
          spark.hadoop.io.compression.codecs: "org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,org.apache.hadoop.io.compress.GzipCodec"
          spark.serializer: "org.apache.spark.serializer.KryoSerializer"
          spark.hadoop.parquet.block.size: "1099511627776"
          spark.sql.files.maxPartitionBytes: "1099511627776"
          spark.sql.files.openCostInBytes: "1099511627776"
        Configurations: []
      - Classification: spark
        ConfigurationProperties:
          maximizeResourceAllocation: true
      Instances:
        AdditionalMasterSecurityGroups:
        - Fn::GetAtt:
          - AllowWebUIs
          - GroupId
        Ec2KeyName:
          Ref: EC2KeyName
        Ec2SubnetId:
          Ref: Subnet
        MasterInstanceGroup:
          InstanceCount: 1
          InstanceType:
            Ref: InstanceType
        CoreInstanceGroup:
          InstanceCount:
            Ref: CoreNodeCount
          InstanceType:
            Ref: InstanceType
          EbsConfiguration:
            EbsOptimized: true
            EbsBlockDeviceConfigs:
            - VolumeSpecification:
                SizeInGB: 
                  Ref: DiskSizeGB
                VolumeType: standard
      Name: spark-hail
      JobFlowRole:
        Ref: rEMREC2InstanceProfile
      ServiceRole:
        Ref: rEMRServiceRole
      ReleaseLabel:
        Ref: EMRReleaseLabel
      LogUri: !Sub "s3://${EMRBucket}"
      Tags:
      - Key: Name
        Value: !Sub "${NameTag}-hail-spark"
      - Key: Owner
        Value:
          Ref: OwnerTag
      - Key: Purpose
        Value:
          Ref: PurposeTag
  EMRCleanup:
    Type: Custom::EMRCleanup
    Properties:
      ServiceToken: !GetAtt EMRCleanupFunction.Arn
  EMRCleanupFunction:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt EMRCleanupExecutionRole.Arn
      Runtime: python2.7
      Timeout: 300
      Code:
        ZipFile: !Sub |
            from __future__ import print_function
            import json
            import boto3
            import cfnresponse
            import time
            def handler(event, context):
                print(json.dumps(event))
                if (event["RequestType"] == "Delete"):
                    try:
                        deleteSecurityGroups("${VPC}")
                    except Exception as e:
                        print("Exception thrown: %s" % str(e))
                        pass
                else:
                    print("RequestType %s, nothing to do" % event["RequestType"])
                time.sleep(30)  # pause for CloudWatch logs
                print('Done')
                responseData={"Data":"OK"}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
            def deleteSecurityGroups(vpcid):
                time.sleep(30)  # delay to avoid dependency race condition
                ec2 = boto3.resource('ec2')
                vpc = ec2.Vpc(vpcid)
                # Fist, delete EMR Default VPC Security Group Rules
                for sg in vpc.security_groups.all():
                   if "ElasticMapReduce" not in sg.group_name:
                       continue
                   print("Deleting rules for SG: " + str(sg))
                   for rule in sg.ip_permissions:
                       try:
                           sg.revoke_ingress(
                               IpPermissions=[{
                                   "IpProtocol":rule["IpProtocol"],
                                   "FromPort":rule["FromPort"],
                                   "ToPort":rule["ToPort"],
                                   "UserIdGroupPairs":rule["UserIdGroupPairs"]}]
                               )
                       except Exception as e:
                           print(str(e))
                # Now, delete the VPC Security Groups
                for sg in vpc.security_groups.all():
                   if "ElasticMapReduce" not in sg.group_name:
                       continue
                   print("Deleting SG: " + str(sg))
                   try:
                       sg.delete()
                   except Exception as e:
                       print(str(e))
                       pass
  EMRCleanupExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: "/"
      Policies:
      - PolicyName: LogsForLambda
        PolicyDocument:
          Version: 2012-10-17
          Statement:
            - Effect: Allow
              Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
              Resource:
                - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*"
                - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/lambda/*:*"
      - PolicyName: EC2DescribeDeleleRevokeSg
        PolicyDocument:
          Version: 2012-10-17
          Statement:
            - Effect: Allow
              Action:
                - ec2:Describe*
                - ec2:DeleteSecurityGroup
                - ec2:RevokeSecurityGroupIngress
              Resource: '*'
              Condition:
                ArnEqualsIfExists:
                  ec2:Vpc: !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:vpc/${VPC}"

Outputs:
  JupyterURL:
    Description: Open Jupyter on your new PySpark/EMR cluster
    Value: !Sub "https://${SparkCluster.MasterPublicDNS}:${JupyterPort}"
  EMRBucket:
    Description: EMR Scratch data and Logs bucket
    Value: !Ref EMRBucket
